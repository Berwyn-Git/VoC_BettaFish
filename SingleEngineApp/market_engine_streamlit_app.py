"""
Streamlit Webç•Œé¢
ä¸ºMarket Agentï¼ˆå¸‚åœºåˆ†æžï¼‰æä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json
import locale
from loguru import logger

# è®¾ç½®UTF-8ç¼–ç çŽ¯å¢ƒ
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['PYTHONUTF8'] = '1'

# è®¾ç½®ç³»ç»Ÿç¼–ç 
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except locale.Error:
    try:
        locale.setlocale(locale.LC_ALL, 'C.UTF-8')
    except locale.Error:
        pass

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from MarketEngine import DeepSearchAgent, Settings
from config import settings
from utils.github_issues import error_with_issue_link


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="å¸‚åœºåˆ†æžAgent",
        page_icon="",
        layout="wide"
    )

    st.title("å¸‚åœºåˆ†æžAgent")
    st.markdown("ä¸“ä¸šçš„å¸‚åœºåˆ†æžAIä»£ç†")
    st.markdown("24å°æ—¶å…¨è‡ªåŠ¨ä»ŽåŒ…æ‹¬å¾®åšã€çŸ¥ä¹Žã€githubã€é…·å®‰ç­‰ 13ä¸ª ç¤¾åª’å¹³å°ã€æŠ€æœ¯è®ºå›å¹¿æ³›çš„çˆ¬å–å¸‚åœºæ•°æ®ï¼Œè¿›è¡Œæ·±åº¦å¸‚åœºåˆ†æž")

    # æ£€æŸ¥URLå‚æ•°
    try:
        # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„query_params
        query_params = st.query_params
        auto_query = query_params.get('query', '')
        auto_search = query_params.get('auto_search', 'false').lower() == 'true'
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆæœ¬
        query_params = st.experimental_get_query_params()
        auto_query = query_params.get('query', [''])[0]
        auto_search = query_params.get('auto_search', ['false'])[0].lower() == 'true'

    # ----- é…ç½®è¢«ç¡¬ç¼–ç  -----
    # å¼ºåˆ¶ä½¿ç”¨ Kimi
    model_name = settings.MARKET_ENGINE_MODEL_NAME or "kimi-k2-0711-preview"
    # é»˜è®¤é«˜çº§é…ç½®
    max_reflections = 2
    max_content_length = 500000  # Kimiæ”¯æŒé•¿æ–‡æœ¬

    # ç®€åŒ–çš„ç ”ç©¶æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ

    # å¦‚æžœæœ‰è‡ªåŠ¨æŸ¥è¯¢ï¼Œä½¿ç”¨å®ƒä½œä¸ºé»˜è®¤å€¼ï¼Œå¦åˆ™æ˜¾ç¤ºå ä½ç¬¦
    display_query = auto_query if auto_query else "ç­‰å¾…ä»Žä¸»é¡µé¢æŽ¥æ”¶åˆ†æžå†…å®¹..."

    # åªè¯»çš„æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ
    st.text_area(
        "å½“å‰æŸ¥è¯¢",
        value=display_query,
        height=100,
        disabled=True,
        help="æŸ¥è¯¢å†…å®¹ç”±ä¸»é¡µé¢çš„æœç´¢æ¡†æŽ§åˆ¶",
        label_visibility="hidden"
    )

    # è‡ªåŠ¨æœç´¢é€»è¾‘
    start_research = False
    query = auto_query

    if auto_search and auto_query and 'auto_search_executed' not in st.session_state:
        st.session_state.auto_search_executed = True
        start_research = True
    elif auto_query and not auto_search:
        st.warning("ç­‰å¾…æœç´¢å¯åŠ¨ä¿¡å·...")

    # éªŒè¯é…ç½®
    if start_research:
        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            logger.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return

        # æ£€æŸ¥é…ç½®ä¸­çš„LLMå¯†é’¥
        if not settings.MARKET_ENGINE_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„çŽ¯å¢ƒå˜é‡ä¸­è®¾ç½®MARKET_ENGINE_API_KEY")
            logger.error("è¯·åœ¨æ‚¨çš„çŽ¯å¢ƒå˜é‡ä¸­è®¾ç½®MARKET_ENGINE_API_KEY")
            return

        # è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥å’Œæ•°æ®åº“é…ç½®
        db_host = settings.DB_HOST
        db_user = settings.DB_USER
        db_password = settings.DB_PASSWORD
        db_name = settings.DB_NAME
        db_port = settings.DB_PORT
        db_charset = settings.DB_CHARSET

        # åˆ›å»ºSettingsé…ç½®ï¼ˆå­—æ®µå¿…é¡»ç”¨å¤§å†™ï¼Œä»¥é€‚é…Settingsç±»ï¼‰
        config = Settings(
            MARKET_ENGINE_API_KEY=settings.MARKET_ENGINE_API_KEY,
            MARKET_ENGINE_BASE_URL=settings.MARKET_ENGINE_BASE_URL,
            MARKET_ENGINE_MODEL_NAME=model_name or settings.MARKET_ENGINE_MODEL_NAME,
            DB_HOST=db_host,
            DB_USER=db_user,
            DB_PASSWORD=db_password,
            DB_NAME=db_name,
            DB_PORT=db_port,
            DB_CHARSET=db_charset,
            DB_DIALECT=settings.DB_DIALECT,
            MAX_REFLECTIONS=max_reflections,
            MAX_CONTENT_LENGTH=max_content_length,
            OUTPUT_DIR="market_engine_streamlit_reports"  # å¸‚åœºåˆ†æžï¼ˆåŽŸinsightï¼‰
        )

        # æ‰§è¡Œç ”ç©¶
        execute_research(query, config)


def execute_research(query: str, config: Settings):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        agent = DeepSearchAgent(config)
        st.session_state.agent = agent

        progress_bar.progress(10)

        # ç”ŸæˆæŠ¥å‘Šç»“æž„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æž„...")
        agent._generate_report_structure(query)
        progress_bar.progress(20)

        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i + 1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")

            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # åæ€å¾ªçŽ¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()

            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)

        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)

        status_text.text("ç ”ç©¶å®Œæˆï¼")

        # æ˜¾ç¤ºç»“æžœ
        display_results(agent, final_report)

    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        error_display = error_with_issue_link(
            f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
            error_traceback,
            app_name="Insight Engine Streamlit App"
        )
        st.error(error_display)
        logger.exception(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æžœ"""
    st.header("å·¥ä½œç»“æŸ")

    # å¯¼å‡ºPDFæŒ‰é’®
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("ðŸ“„ å¯¼å‡ºPDF", type="primary", use_container_width=True):
            try:
                from utils.pdf_export import export_report_to_pdf, PDF_EXPORT_AVAILABLE
                
                if not PDF_EXPORT_AVAILABLE:
                    st.error("PDFå¯¼å‡ºåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install markdown weasyprint æˆ– pip install reportlab")
                else:
                    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                    st.info(f"ðŸ“ æŠ¥å‘Šå†…å®¹é•¿åº¦: {len(final_report)} å­—ç¬¦")
                    st.info(f"ðŸ“ è¾“å‡ºç›®å½•: {agent.config.OUTPUT_DIR}")
                    st.info(f"ðŸ” æŸ¥è¯¢å†…å®¹: {agent.state.query}")
                    
                    with st.spinner("æ­£åœ¨ç”ŸæˆPDF..."):
                        pdf_path = export_report_to_pdf(
                            report_content=final_report,
                            output_dir=agent.config.OUTPUT_DIR,
                            query=agent.state.query,
                            engine_name="market"
                        )
                        
                        if pdf_path:
                            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                            if os.path.exists(pdf_path):
                                # è¯»å–PDFæ–‡ä»¶å¹¶æä¾›ä¸‹è½½
                                with open(pdf_path, 'rb') as pdf_file:
                                    pdf_data = pdf_file.read()
                                    file_size = len(pdf_data)
                                    st.download_button(
                                        label="ðŸ“¥ ä¸‹è½½PDF",
                                        data=pdf_data,
                                        file_name=os.path.basename(pdf_path),
                                        mime="application/pdf",
                                        use_container_width=True
                                    )
                                st.success(f"âœ… PDFå·²ç”Ÿæˆ: {os.path.basename(pdf_path)}")
                                st.info(f"ðŸ“ æ–‡ä»¶ä½ç½®: {pdf_path}")
                                st.info(f"ðŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
                            else:
                                st.error(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                                logger.error(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                                # å°è¯•åˆ—å‡ºç›®å½•å†…å®¹
                                output_dir_abs = os.path.abspath(agent.config.OUTPUT_DIR)
                                if os.path.exists(output_dir_abs):
                                    files = os.listdir(output_dir_abs)
                                    st.warning(f"ç›®å½• {output_dir_abs} ä¸­çš„æ–‡ä»¶: {files[:10]}")
                        else:
                            st.error("âŒ PDFç”Ÿæˆå¤±è´¥ï¼Œexport_report_to_pdf è¿”å›ž None")
                            logger.error("export_report_to_pdf è¿”å›ž None")
                            st.info("ðŸ’¡ æç¤º: è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä»¥èŽ·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")
            except Exception as e:
                error_msg = str(e)
                st.error(f"âŒ å¯¼å‡ºPDFæ—¶å‡ºé”™: {error_msg}")
                logger.exception(f"å¯¼å‡ºPDFå¤±è´¥: {error_msg}")
                import traceback
                st.code(traceback.format_exc(), language="python")

    # ç»“æžœæ ‡ç­¾é¡µï¼ˆå·²ç§»é™¤ä¸‹è½½é€‰é¡¹ï¼‰
    tab1, tab2 = st.tabs(["ç ”ç©¶å°ç»“", "å¼•ç”¨ä¿¡æ¯"])

    with tab1:
        st.markdown(final_report)

    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i + 1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..."
                if len(paragraph.research.latest_summary) > 300
                else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)

        # æœç´¢åŽ†å²
        st.subheader("æœç´¢åŽ†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)

        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i + 1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**",
                             search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)


if __name__ == "__main__":
    main()
